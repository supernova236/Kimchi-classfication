# -*- coding: utf-8 -*-
"""kimchi_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YQ244-8-UjmKaojHINFSRbm04EV0A29d

# pytorch CNN image classification
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')

import os

# Navigate to the directory where my dataset is located
dataset_path = '/content/drive/MyDrive/kimchi_classification/dataset'

os.chdir(dataset_path)



# %pwd

import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np
from torch.utils.data import ConcatDataset, DataLoader, Subset
from torchvision import datasets, transforms
from itertools import chain
from tqdm import tqdm

device = 'cuda' if torch.cuda.is_available() else 'cpu'

torch.manual_seed(100)

if device == 'cuda':
    torch.cuda.manual_seed_all(100)

learning_rate = 0.001
training_epochs = 15
batch_size = 35
num_workers = 2
num_folds = 5

transform = transforms.ToTensor()


# Load the train, valid, test dataset in KIMCHI dataset
kimch_train = datasets.ImageFolder(root=os.path.join(dataset_path, 'train'), transform=transform)
kimch_valid = datasets.ImageFolder(root=os.path.join(dataset_path, 'val'), transform=transform)
kimch_test = datasets.ImageFolder(root=os.path.join(dataset_path, 'test'), transform=transform)

#Combine train and validation sets for do K-Fold cross-valdation

train_loader = DataLoader(kimch_train, batch_size=batch_size, shuffle=True, num_workers=2)
val_loader = DataLoader(kimch_valid, batch_size=batch_size, shuffle=False, num_workers=2)
test_loader = DataLoader(kimch_test, batch_size=batch_size, shuffle=False, num_workers=2)

class kimchi_CNN(torch.nn.Module):

    def __init__(self, num_classes):
        super(kimchi_CNN, self).__init__()

        # First Layer
        # Input image size = 64 x 64 x 3
        # number of kennels = 8
        # Outputsize = 32 x 32 x 16

        self.layer1 = torch.nn.Sequential(
            torch.nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2),
            torch.nn.Dropout(p=0.25))

        # Second Layer
        # Input image size = 32 x 32 x 16
        # number of kennels = 32
        # Outputsize = 16 x 16 x 32


        self.layer2 = torch.nn.Sequential(
            torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2))

        # Third Layer
        # Input image size = 16 x 16 x 32
        # number of kennels = 64
        # Outputsize = 8 x 8 x 64

        self.layer3 = torch.nn.Sequential(
            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2),
            torch.nn.Dropout(p=0.25))


        # Fourth Layer
        # Input image size = 8 x 8 x 64
        # number of kennels = 64
        # Outputsize = 5 x 5 x 128

        self.layer4 = torch.nn.Sequential(
            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))

        # Fifth Layer
        # Drop out

        self.fc1 = torch.nn.Linear(5 * 5 * 128, 800, bias=True)
        torch.nn.init.xavier_uniform_(self.fc1.weight)
        self.layer5 = torch.nn.Sequential(
            self.fc1,
            torch.nn.ReLU(),
            torch.nn.Dropout(p=0.5))

        # Fully connected layer 11 outputs
        self.fc2 = torch.nn.Linear(800, num_classes, bias=True)
        torch.nn.init.xavier_uniform_(self.fc2.weight)



    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = out.view(out.size(0), -1)
        out = self.layer5(out)
        out = self.fc2(out)
        return out

model = kimchi_CNN(num_classes = 11).to(device)

criterion = torch.nn.CrossEntropyLoss().to(device)
# Cross entropy loss
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = 0.001)
#learning_Rate = 0.001

# Training and validation session


train_accuracies = []
val_accuracies = []

for epoch in range(training_epochs):
    #training_epochs = 15

    cost_train = 0
    cost_val = 0
    total_correct_train = 0
    total_samples_train = 0

    total_batch = len(train_loader)

    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{training_epochs}', unit='batch'):
        # images is min-batch
        # labels
        X = images.to(device)
        Y = labels.to(device)

        optimizer.zero_grad()
        hypothesis = model(X)
        cost = criterion(hypothesis, Y)
        cost.backward()
        optimizer.step()

        cost_train += cost / total_batch

        _, predicted = torch.max(hypothesis.data, 1)
        total_samples_train += labels.size(0)

        predicted = predicted.to(labels.device)
        total_correct_train += (predicted == labels).sum().item()


    train_accuracy = total_correct_train / total_samples_train
    train_accuracies.append(train_accuracy)



    model.eval()  # Set the model to evaluation mode

    total_correct_val = 0
    total_samples_val = 0

    with torch.no_grad():
        for val_images, val_labels in val_loader:
            X_val = val_images.to(device)
            Y_val = val_labels.to(device)

            val_hypothesis = model(X_val)
            val_cost = criterion(val_hypothesis, Y_val)

            cost_val += val_cost / len(val_loader)

            # Calculate validation accuracy
            _, val_predicted = torch.max(val_hypothesis.data, 1)
            total_samples_val += val_labels.size(0)

            val_predicted = val_predicted.to(val_labels.device)
            total_correct_val += (val_predicted == val_labels).sum().item()

        val_accuracy = total_correct_val / total_samples_val
        val_accuracies.append(val_accuracy)





    print(f'[Epoch: {epoch + 1:>4}], Train Loss: {cost_train:.6f}, Train Accuracy: {train_accuracy:.2%}, Val Loss: {cost_val:.6f}, Val Accuracy: {val_accuracy:.2%}')

plt.plot(range(1, training_epochs + 1), train_accuracies, label='Training Accuracy', marker='o')
plt.plot(range(1, training_epochs + 1), val_accuracies, label='Validation Accuracy', marker='o')

plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title(f'Training and Validation Accuracy Over Epochs')

# Adding a legend
plt.legend()

# Display the plot
plt.show()

# # Test session

# Lists to store per-class accuracy
class_correct = [0] * len(kimch_test.classes)
class_total = [0] * len(kimch_test.classes)

model.eval()  # Set the model to evaluation mode
correct = 0
total = 0

with torch.no_grad():
    for test_images, test_labels in test_loader:

        X_test = test_images.to(device)
        Y_test = test_labels.to(device)
        test = model(X_test)
        _, test_predicted = torch.max(test.data, 1)
        test_predicted = test_predicted.to(test_labels.device)
        total += test_labels.size(0)
        correct += (test_predicted == test_labels).sum().item()

        # Calculate class-wise accuracy
        for i in range(len(test_labels)):
            label = test_labels[i].item()
            class_correct[label] += int(test_predicted[i] == label)
            class_total[label] += 1



avg_test_accuracy = correct / total
print(f'Test Accuracy: {100 * avg_test_accuracy:.2f}%')

# Plotting
class_names = kimch_test.classes
class_accuracies = [class_correct[i] / class_total[i] for i in range(len(class_correct))]

# Plot overall accuracy
plt.figure(figsize=(20, 5))
plt.bar(['Average'] + class_names, [avg_test_accuracy] + class_accuracies)
plt.title('Testing Accuracy')
plt.xlabel('Classes')
plt.ylabel('Accuracy')
plt.ylim(0, 1.0)
plt.show()